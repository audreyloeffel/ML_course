{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCML PROJECT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training data into feature matrix, class labels, and event ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250000, 30)\n"
     ]
    }
   ],
   "source": [
    "from proj1_helpers import *\n",
    "DATA_TRAIN_PATH = '../data/train.csv' # TODO: download train data and supply path here \n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)\n",
    "print(tX.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Normalization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize(tX):\n",
    "    nullValue = -999\n",
    "    tX[tX==nullValue] = 0\n",
    "    m = np.mean(tX, axis=0)\n",
    "    tX_centered = tX - m\n",
    "\n",
    "    tX_centered[tX_centered==0] = float('nan')\n",
    "    tX_std= np.nanstd(tX_centered, axis=0)\n",
    "    tX_centered[tX_centered==float('nan')] = 0\n",
    "    normalized = tX_centered / tX_std\n",
    "    return normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Test normalize function\n",
    "#print(tX)\n",
    "#norm = normalize(tX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Probably useless\n",
    "\n",
    "def removeNullColumns(tX, threshold):\n",
    "    nullValue = -999\n",
    "    rows, columns = tX.shape\n",
    "    toDelete = []\n",
    "    \n",
    "    for column in range(0, columns):\n",
    "        xi = tX[column]\n",
    "        xi[xi == nullValue] = np.nan\n",
    "        m = np.nansum(xi)\n",
    "        if (m / rows > threshold):\n",
    "            toDelete.append(column)\n",
    "            \n",
    "    print(\"Columns deleted: \", toDelete)\n",
    "    new = np.delete(tX, toDelete)  \n",
    "    print(\"new\", new.shape)\n",
    "    return new\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Probably useless too\n",
    "\n",
    "def replaceNullValue(tX):\n",
    "    nullValue = -999\n",
    "    rows, columns = tX.shape\n",
    "    x = tX\n",
    "    \n",
    "    for column in range(0, columns):\n",
    "        xi = x[column]\n",
    "        xi[xi == nullValue] = np.nan\n",
    "        mean = np.mean(xi)\n",
    "        nanIndex = np.where(np.isnan(xi))\n",
    "        xi[nanIndex] = mean\n",
    "        x[column] = xi\n",
    "    return tX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from least_squares import *\n",
    "from regression import *\n",
    "\n",
    "def learn_with(method, y, tx, gamma=0.1, max_iters=5, lambda_=0.1):\n",
    "    if method == 'least_squares':\n",
    "        return least_squares(y, tx)\n",
    "    \n",
    "    if method == 'least_square_GD': \n",
    "        return least_squares_GD(y, tx, gamma, max_iters)\n",
    "\n",
    "    if method == 'least_square_SGD': \n",
    "        return least_squares_SGD(y, tx, gamma, max_iters)\n",
    "\n",
    "    if method == 'logistic_regression': \n",
    "        return logistic_regression(y, tx, gamma, max_iters)\n",
    "\n",
    "    if method == 'pen_logistic_regression': \n",
    "        return pen_logisitic_regression(y, tx, lambda_, gamma, max_iters)\n",
    "    \n",
    "    if method == 'ridge_regression': \n",
    "        return ridge_regression(y, tx, lambda_)\n",
    "    \n",
    "    return least_squares(y, tx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250000, 30)\n",
      "(31,)\n"
     ]
    }
   ],
   "source": [
    "from helpers import standardize\n",
    "\n",
    "normalizedtX = normalize(tX)\n",
    "print(normalizedtX.shape)\n",
    "x = np.hstack((np.ones((normalizedtX.shape[0],1)), normalizedtX))\n",
    "loss, weights = learn_with(\"least_square_GD\", y, x)\n",
    "print(weights.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimazing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Improving Least_Squares\n",
    "\n",
    "We search the gamma parameter that minimize the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gamma = 0.0,  loss = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.]\n",
      "gamma = 0.2631578947368421,  loss = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.]\n",
      "gamma = 0.5263157894736842,  loss = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.]\n",
      "gamma = 0.7894736842105263,  loss = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.]\n",
      "gamma = 1.0526315789473684,  loss = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.]\n",
      "gamma = 1.3157894736842104,  loss = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.]\n",
      "gamma = 1.5789473684210527,  loss = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.]\n",
      "gamma = 1.8421052631578947,  loss = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.]\n",
      "gamma = 2.1052631578947367,  loss = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.]\n",
      "gamma = 2.3684210526315788,  loss = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.]\n",
      "gamma = 2.631578947368421,  loss = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.]\n",
      "gamma = 2.894736842105263,  loss = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.]\n",
      "gamma = 3.1578947368421053,  loss = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.]\n",
      "gamma = 3.4210526315789473,  loss = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.]\n",
      "gamma = 3.6842105263157894,  loss = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.]\n",
      "gamma = 3.9473684210526314,  loss = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.]\n",
      "gamma = 4.2105263157894735,  loss = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.]\n",
      "gamma = 4.473684210526316,  loss = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.]\n",
      "gamma = 4.7368421052631575,  loss = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.]\n",
      "gamma = 5.0,  loss = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f2e853a6a20>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhkAAAFkCAYAAACNTikJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAAPYQAAD2EBqD+naQAAGrZJREFUeJzt3X2QZ1V95/H3R54UswzEEUZCskaz6BCNMi24EyMJEp0l\nWmJijLbCbmTLCorINmWtGze7+FCsWZUHUali0RUopF0XImqITgQVnwbQbsAyDCy78iCaGRnAwccA\nw3f/uLfJj6Z7en49fbqx5/2q+tXMnPs9p8+9RTGfOffc301VIUmStNAet9QTkCRJy5MhQ5IkNWHI\nkCRJTRgyJElSE4YMSZLUhCFDkiQ1YciQJElNGDIkSVIThgxJktSEIUOSJDXRPGQkOTHJrUl+nuTq\nJIfNUf+qJBv7+huSHD1Dzeokn07yoyQ/SXJNkoPanYUkSRpW05CR5NXA6cCpwKHADcD6JCtnqV8L\nXAycBzwXuAy4LMkhAzVPB74K3AgcATwbeDfwi3ZnIkmShpWWL0hLcjVwTVWd3P85wPeAs6vqvTPU\nfwLYu6pePtC2Abiuqt7U/3kcuL+q/l2ziUuSpJ3WbCUjyR7ACHDlVFt1ieYKYO0s3db2xwetn6rv\nQ8pLgVuSfD7J5v4WzDELPX9JkrRzdm849kpgN2DztPbNwDNm6bNqlvpV/e/3B34FeBvwn4H/CBwN\n/E2SP6iqr840aJInAeuA2/C2iiRJw3g88FRgfVXdPUzHliFjNgGGuUczWD+18nJZVZ3d//7bSX4X\nOIFur8ZM1gEfH3aikiTpYa+j2ze5w1qGjC3ANuCAae378+jViimb5qjfAjwIbJxWsxF4wXbmchvA\nRRddxOrVq7c7aS2csbExzjzzzKWexi7Fa774vOaLz2u+uDZu3Mixxx4L/d+lw2gWMqrqgSQTwFHA\nZ+DhPRVHAWfP0m3DDMdf3LdPjflNHn275WDg9u1M5xcAq1evZs2aNUOeieZrxYoVXu9F5jVffF7z\nxec1XzJDbzdofbvkDOCCPmxcC4wBewPnAyS5ELizqt7e138AuCrJKcDlwCjd5tE3DIz5PuATSb4K\nfIluT8bLgN9vfC6SJGkITUNGVX2y/06Md9HdBrkeWFdVd/UlB9Hd/piq35BkFDit/9wCHFNVNw7U\nXJbkBODtdKHkZuBPqmpDy3ORJEnDab7xs6rOAc6Z5diLZmi7FLh0jjHPp18NkSRJj02+u0TNjI6O\nLvUUdjle88XnNV98XvNfHk2/8fOxIskaYGJiYsLNQpIkDWFycpKRkRGAkaqaHKavKxmSJKkJQ4Yk\nSWrCkCFJkpowZEiSpCYMGZIkqQlDhiRJasKQIUmSmjBkSJKkJgwZkiSpCUOGJElqwpAhSZKaMGRI\nkqQmDBmSJKkJQ4YkSWrCkCFJkpowZEiSpCYMGZIkqQlDhiRJasKQIUmSmjBkSJKkJgwZkiSpCUOG\nJElqwpAhSZKaMGRIkqQmDBmSJKkJQ4YkSWrCkCFJkpowZEiSpCYMGZIkqQlDhiRJasKQIUmSmjBk\nSJKkJgwZkiSpCUOGJElqwpAhSZKaMGRIkqQmDBmSJKkJQ4YkSWrCkCFJkppYlJCR5MQktyb5eZKr\nkxw2R/2rkmzs629IcvR2as9N8lCStyz8zCVJ0nw1DxlJXg2cDpwKHArcAKxPsnKW+rXAxcB5wHOB\ny4DLkhwyQ+0rgMOB77eZvSRJmq/FWMkYA86tqgur6ibgBOBnwPGz1J8MfK6qzqiqm6vqVGASePNg\nUZJfA84GXgs82Gz2kiRpXpqGjCR7ACPAlVNtVVXAFcDaWbqt7Y8PWj9YnyTAhcB7q2rjQs5ZkiQt\njNYrGSuB3YDN09o3A6tm6bNqB+r/E3B/VX1oISYpSZIW3u5L9HMD1Hzqk4wAb6Hb3zGUsbExVqxY\n8Yi20dFRRkdHhx1KkqRlZ3x8nPHx8Ue0bd26dd7jtQ4ZW4BtwAHT2vfn0asVUzbNUf97wJOB73V3\nTYButeSMJP+hqp4222TOPPNM1qxZs+OzlyRpFzLTP7wnJycZGRmZ13hNb5dU1QPABHDUVFu/n+Io\n4BuzdNswWN97cd8O3V6M3wGeM/D5AfBeYN1CzV2SJO2cxbhdcgZwQZIJ4Fq6p032Bs4HSHIhcGdV\nvb2v/wBwVZJTgMuBUbrNo28AqKp7gXsHf0CSB4BNVXVL87ORJEk7pHnIqKpP9t+J8S662yDXA+uq\n6q6+5CAGHkGtqg1JRoHT+s8twDFVdeP2fkyTyUuSpHlblI2fVXUOcM4sx140Q9ulwKVDjD/rPgxJ\nkrQ0fHeJJElqwpAhSZKaMGRIkqQmDBmSJKkJQ4YkSWrCkCFJkpowZEiSpCYMGZIkqQlDhiRJasKQ\nIUmSmjBkSJKkJgwZkiSpCUOGJElqwpAhSZKaMGRIkqQmDBmSJKkJQ4YkSWrCkCFJkpowZEiSpCYM\nGZIkqQlDhiRJasKQIUmSmjBkSJKkJgwZkiSpCUOGJElqwpAhSZKaMGRIkqQmDBmSJKkJQ4YkSWrC\nkCFJkpowZEiSpCYMGZIkqQlDhiRJasKQIUmSmjBkSJKkJgwZkiSpCUOGJElqwpAhSZKaMGRIkqQm\nDBmSJKmJRQkZSU5McmuSnye5Oslhc9S/KsnGvv6GJEcPHNs9yX9P8u0kP0ny/SQXJHlK+zORJEk7\nqnnISPJq4HTgVOBQ4AZgfZKVs9SvBS4GzgOeC1wGXJbkkL5k7779nf14fww8A/h0w9OQJElDWoyV\njDHg3Kq6sKpuAk4AfgYcP0v9ycDnquqMqrq5qk4FJoE3A1TVfVW1rqourapbqura/thIkoPan44k\nSdoRTUNGkj2AEeDKqbaqKuAKYO0s3db2xwet3049wL5AAT+a92QlSdKCar2SsRLYDdg8rX0zsGqW\nPquGqU+yF/DXwMVV9ZP5T1WSJC2kpXq6JHQrDztVn2R34H/3x960MFOTJEkLYffG428BtgEHTGvf\nn0evVkzZtCP1AwHj14EX7cgqxtjYGCtWrHhE2+joKKOjo3N1lSRp2RsfH2d8fPwRbVu3bp33eOm2\nSLST5Grgmqo6uf9zgDuAs6vqfTPUfwJ4QlUdM9D2deCGqnpT/+epgPE04MiqumeOOawBJiYmJliz\nZs0CnZkkScvf5OQkIyMjACNVNTlM39YrGQBnABckmQCupXvaZG/gfIAkFwJ3VtXb+/oPAFclOQW4\nHBil2zz6hr5+N+BSusdYXwbskWRq5eOeqnpgEc5JkiTNoXnIqKpP9t+J8S662yDXA+uq6q6+5CDg\nwYH6DUlGgdP6zy3AMVV140D9y/rfX9//OrVn40jgKw1PR5Ik7aDFWMmgqs4Bzpnl2ItmaLuUbrVi\npvrb6Z5YkSRJj2G+u0SSJDVhyJAkSU0YMiRJUhOGDEmS1IQhQ5IkNWHIkCRJTRgyJElSE4YMSZLU\nhCFDkiQ1YciQJElNGDIkSVIThgxJktSEIUOSJDVhyJAkSU0YMiRJUhOGDEmS1IQhQ5IkNWHIkCRJ\nTRgyJElSE4YMSZLUhCFDkiQ1YciQJElNGDIkSVIThgxJktSEIUOSJDVhyJAkSU0YMiRJUhOGDEmS\n1IQhQ5IkNWHIkCRJTRgyJElSE4YMSZLUhCFDkiQ1YciQJElNGDIkSVIThgxJktSEIUOSJDVhyJAk\nSU0YMiRJUhOGDEmS1IQhQ5IkNbEoISPJiUluTfLzJFcnOWyO+lcl2djX35Dk6Blq3pXkB0l+luQL\nSX6r3RlIkqRhNQ8ZSV4NnA6cChwK3ACsT7Jylvq1wMXAecBzgcuAy5IcMlDzNuDNwF8AhwM/7cfc\ns+GpSJKkISzGSsYYcG5VXVhVNwEnAD8Djp+l/mTgc1V1RlXdXFWnApN0oWKw5t1V9dmq+g7wb4ED\ngVc0OwtJkjSUpiEjyR7ACHDlVFtVFXAFsHaWbmv744PWT9UneRqwatqY9wHXbGdMSZK0yHZvPP5K\nYDdg87T2zcAzZumzapb6Vf3vDwBqjpoZbdw4x2wlSdIj7Mzfna1DxmxCFxQWsn7OmmOPHQNWTGsd\n7T+SJO3qxvvPoK3zHq11yNgCbKNbfRi0P49eiZiyaY76TXSB4oBpY+wPXLe9yVx00ZmsXr1m7llL\nkrRLevQ/vDdunOTYY0fmNVrTkFFVDySZAI4CPgOQJP2fz56l24YZjr+4b6eqbk2yqa/5dj/mPsDz\ngQ9vbz6rV8MaM4YkSYtiMW6XnAFc0IeNa+meNtkbOB8gyYXAnVX19r7+A8BVSU4BLqeLVCPAGwbG\nPAv4qyT/F7gNeDdwJ/Dp1icjSZJ2TPOQUVWf7L8T4110tziuB9ZV1V19yUHAgwP1G5KMAqf1n1uA\nY6rqxoGa9ybZGzgX2Bf4KnB0Vd3f+nwkSdKOWZSNn1V1DnDOLMdeNEPbpcClc4z5DuAdCzA9SZLU\ngO8ukSRJTRgyJElSE4YMSZLUhCFDkiQ1YciQJElNGDIkSVIThgxJktSEIUOSJDVhyJAkSU0YMiRJ\nUhOGDEmS1IQhQ5IkNWHIkCRJTRgyJElSE4YMSZLUhCFDkiQ1YciQJElNGDIkSVIThgxJktSEIUOS\nJDVhyJAkSU0YMiRJUhOGDEmS1IQhQ5IkNWHIkCRJTRgyJElSE4YMSZLUhCFDkiQ1YciQJElNGDIk\nSVIThgxJktSEIUOSJDVhyJAkSU0YMiRJUhOGDEmS1IQhQ5IkNWHIkCRJTRgyJElSE4YMSZLUhCFD\nkiQ1YciQJElNNA0ZSfZL8vEkW5Pcm+QjSZ44R5+9knw4yZYkP05ySZL9B47/TpKLk9yR5GdJ/iHJ\nW1qehyRJGl7rlYyLgdXAUcBLgSOAc+foc1Zf+8q+/kDgbwaOjwA/BF4HHAKcBrwnyZsWdOaSJGmn\n7N5q4CTPBNYBI1V1Xd92EnB5krdW1aYZ+uwDHA+8pqqu6tteD2xMcnhVXVtVH5vW7bYkvwv8CXBO\nq/ORJEnDabmSsRa4dypg9K4ACnj+LH1G6ILPlVMNVXUzcEc/3mxWAPfs1GwlSdKCaraSAayiu63x\nsKraluSe/thsfe6vqvumtW+erU+/ivFnwB/t3HQlSdJCGjpkJHkP8LbtlBTdPoxZh+hrhvqxM/VJ\n8izgMuAdVXXlo3pNMzY2xooVKx7RNjo6yujo6JDTkSRp+RkfH2d8fPwRbVu3bp33eKka7u/7JE8C\nnjRH2XeB44D3V9XDtUl2A34B/GlVfXqGsY+ku6Wy3+BqRpLbgDOr6gMDbYcAXwT+R1X91znmvAaY\nmJiYYM2aNXNMXZIkTZmcnGRkZAS6PZaTw/QdeiWjqu4G7p6rLskGYN8khw7syziKblXimlm6TQAP\n9nWf6sc5GPgNYMPA2L9Nt2/jY3MFDEmStDSabfysqpuA9cB5SQ5L8gLgg8D41JMlSQ5MsjHJ8/o+\n9wEfBc5I8gdJRoCPAV+vqmv7Pr8NfAn4e+CsJAf0n5WtzkWSJA2v5cZPgNcCH6K7BfIQcAlw8sDx\nPYCDgb0H2saAbX3tXsDngRMHjv8p3e2a1/WfKbcDT1vY6UuSpPlqGjKq6kfAsds5fjuw27S2fwJO\n6j8z9Xkn8M4FnKYkSWrAd5dIkqQmDBmSJKkJQ4YkSWrCkCFJkpowZEiSpCYMGZIkqQlDhiRJasKQ\nIUmSmjBkSJKkJgwZkiSpCUOGJElqwpAhSZKaMGRIkqQmDBmSJKkJQ4YkSWrCkCFJkpowZEiSpCYM\nGZIkqQlDhiRJasKQIUmSmjBkSJKkJgwZkiSpCUOGJElqwpAhSZKaMGRIkqQmDBmSJKkJQ4YkSWrC\nkCFJkpowZEiSpCYMGZIkqQlDhiRJasKQIUmSmjBkSJKkJgwZkiSpCUOGJElqwpAhSZKaMGRIkqQm\nDBmSJKkJQ4YkSWrCkCFJkppoGjKS7Jfk40m2Jrk3yUeSPHGOPnsl+XCSLUl+nOSSJPvPUvurSe5M\nsi3JPm3OQpIkzUfrlYyLgdXAUcBLgSOAc+foc1Zf+8q+/kDg0llqPwpcvyAzlSRJC6pZyEjyTGAd\n8O+r6ltV9Q3gJOA1SVbN0mcf4HhgrKquqqrrgNcDL0hy+LTaNwIrgNNbnYMkSZq/lisZa4F7+6Aw\n5QqggOfP0mcE2B24cqqhqm4G7ujHAyDJIcBfAccBDy3stCVJ0kJoGTJWAT8cbKiqbcA9/bHZ+txf\nVfdNa9881SfJnnS3Yd5aVd9f0BlLkqQFM3TISPKeJA9t57MtycHbG4JuNWOoHzvQ56+BG6tqfODY\n4K+SJOkxYPd59Hk/8LE5ar4LbAIe8VRIkt2A/ehWJmayCdgzyT7TVjP2H+hzJPCsJK+aGrb/3JXk\ntKp652yTGhsbY8WKFY9oGx0dZXR0dI7TkSRp+RsfH2d8fPwRbVu3bp33eKkadlFhBwfuNn7+A/C8\nqX0ZSV4C/B1wUFVtmqHPPsBdwGuq6lN928HATcDzq+qbSX4TeMJAt8PpnjJZC3y3qrbMMO4aYGJi\nYoI1a9Ys5GlKkrSsTU5OMjIyAjBSVZPD9J3PSsYOqaqbkqwHzuufBNkT+CAwPhUwkhxIt8nzuP4J\nlPuSfBQ4I8m9wI+Bs4GvV9U3+3FvHfw5SZ5Mt5Jx0wx7OSRJ0hJpFjJ6rwU+RPdUyUPAJcDJA8f3\nAA4G9h5oGwO29bV7AZ8HTpzj57RZjpEkSfPWNGRU1Y+AY7dz/HZgt2lt/0T3fRon7eDPuGr6GJIk\naen57hJJktSEIUOSJDVhyJAkSU0YMiRJUhOGDEmS1IQhQ5IkNWHIkCRJTRgyJElSE4YMSZLUhCFD\nkiQ1YciQJElNGDIkSVIThgxJktSEIUOSJDVhyJAkSU0YMiRJUhOGDEmS1IQhQ5IkNWHIkCRJTRgy\nJElSE4YMSZLUhCFDkiQ1YciQJElNGDIkSVIThgxJktSEIUOSJDVhyJAkSU0YMiRJUhOGDEmS1IQh\nQ5IkNWHIkCRJTRgyJElSE4YMSZLUhCFDkiQ1YciQJElNGDIkSVIThgxJktSEIUOSJDVhyJAkSU0Y\nMiRJUhOGDDUzPj6+1FPY5XjNF5/XfPF5zX95NAsZSfZL8vEkW5Pcm+QjSZ44R5+9knw4yZYkP05y\nSZL9Z6j78yQ3JPl5kk1JPtjqPDR//o9g8XnNF5/XfPF5zX95tFzJuBhYDRwFvBQ4Ajh3jj5n9bWv\n7OsPBC4dLEhyCvBu4L8BhwB/CKxfyIlLkqSdt3uLQZM8E1gHjFTVdX3bScDlSd5aVZtm6LMPcDzw\nmqq6qm97PbAxyeFVdW2SfekCxkur6ssD3b/T4jwkSdL8tVrJWAvcOxUwelcABTx/lj4jdKHnyqmG\nqroZuKMfD+AlQIBfT3Jjku8l+V9JDlroE5AkSTunyUoGsAr44WBDVW1Lck9/bLY+91fVfdPaNw/0\n+U1gN+AvgbcA9wGnAV9I8uyqenCWsR8PsHHjxmHPQzth69atTE5OLvU0dile88XnNV98XvPFNfB3\n5+OH7TtUyEjyHuBt2ykpun0Ysw7R1wz1Ywf6PI5uzidV1ZX9nEaBTcCRwBdmGeOpAMcee+yQP1o7\na2RkZKmnsMvxmi8+r/ni85oviacC3ximw7ArGe8HPjZHzXfp/tJ/xFMhSXYD9qNbmZjJJmDPJPtM\nW83Yf6DPP/a/PhyrqmpLki3Ab2xnTuuB1wG3Ab+YY/6SJOmfPZ4uYAz9kMVQIaOq7gbunqsuyQZg\n3ySHDuzLOIpuVeKaWbpNAA/2dZ/qxzmYLjxs6Gu+3v/6DOAHfc2vAiuB2+eY98VzzVuSJM1oqBWM\nKaka9u7FDg6c/B3dKsQbgT2B/wlcW1XH9ccPpNvkeVxVfatvOwc4Gng98GPgbOChqnrhwLifAp4O\n/EVf8x7gXwKHVtW2JicjSZKG1vJ7Ml4L3ET3VMnfAl+hCwZT9gAOBvYeaBvray8Bvky3WvHKaeMe\nR7ca8rfAl+hufxxtwJAk6bGl2UqGJEnatfnuEkmS1IQhQ5IkNbHsQ0aSE5Pc2r9M7eokhy31nJaz\nJC9M8pkk30/yUJKXL/Wclrskf5nk2iT3Jdmc5FP9k1lqJMkJ/Usat/afbyT5N0s9r11F/9/8Q0nO\nWOq5LGdJTu2v8+DnxmHGWNYhI8mrgdOBU4FDgRuA9UlWLunElrcnAtcDJzL8F69pfl4IfJDuK/v/\nkG5T9d8necKSzmp5+x7dFxOO9J8vAp9Osr0vI9QC6P+h+Aa6/5+rve8AB9B98/Yq4PeG6bysN34m\nuRq4pqpO7v8cuv85nF1V713Sye0CkjwEvKKqPrPUc9mV9CH6h8ARVfW1pZ7PriLJ3cBbq2quLyzU\nPCX5FbrvVHoj8F+A66rqlKWd1fKV5FTgmKpaM98xlu1KRpI96P6FMfjCtaJ7pHbtbP2kZWBfulWk\ne5Z6IruCJI9L8hq6x/E3zFWvnfJh4LNV9cWlnsgu5F/1t7//X5KLkvz6MJ1bvSDtsWAl3cvUpn+N\n+Wa6bwyVlp1+te4s4GtVNdS9Uw0nybPoQsXj6b4Y8I+r6qalndXy1Qe55wLPW+q57EKuBv4cuBl4\nCvAO4CtJnlVVP92RAZZzyJjNfF7SJv2yOAc4BHjBUk9kF3AT8By6laNXAhcmOcKgsfCSHEQXnl9c\nVQ8s9Xx2FVU1+K6S7yS5lu4VHn/G3O8xA5Z3yNgCbKPbsDJo8IVr0rKR5EPAHwEvrKp/nKteO6eq\nHqR7ISTAZJLDgZPp9gtoYY0ATwYm+tU66Faqj0jyZmCvWs4bDB8jqmprkv8D/NaO9lm2ezL6tDtB\n98I14OGl5KOY54tepMeqPmAcAxxZVXcs9Xx2UY8D9lrqSSxTVwDPprtd8pz+8y3gIuA5BozF0W+8\nfTr//Eb0OS3nlQyAM4ALkkwA19K9G2Vv4PylnNRyluSJdCl36l8bT0vyHOCeqvre0s1s+epfLDgK\nvBz4aZKp1butVfWLpZvZ8pXkNOBzdE+r/QvgdcDvAy9ZynktV/39/0fsMUryU+Duqtq4NLNa/pK8\nD/gs3S2SXwPeSfe29PEdHWNZh4yq+mT/ON+76G6bXA+sq6q7lnZmy9rz6F5cV/3n9L79AuD4pZrU\nMncC3bX+8rT21wMXLvpsdg0H0F3bpwBbgW8DL/Gph0Xl6kV7BwEXA08C7gK+Bvzrqrp7RwdY1t+T\nIUmSls6y3ZMhSZKWliFDkiQ1YciQJElNGDIkSVIThgxJktSEIUOSJDVhyJAkSU0YMiRJUhOGDEmS\n1IQhQ5IkNWHIkCRJTfx/9mFux4Lm260AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2ea2b2da90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nbPoints = 20\n",
    "gammaRange = np.linspace(0, 5, nbPoints)\n",
    "losses = np.zeros(nbPoints)\n",
    "    \n",
    "for i in range(nbPoints):\n",
    "    gamma = gammaRange[i]\n",
    "    # crossvalidation\n",
    "    #losses[i] = loss\n",
    "    print(\"gamma = {},  loss = {}\".format(gamma, loss))\n",
    "\n",
    "plt.plot(gammaRange, losses)\n",
    "bestGammaIdx = np.where(losses == np.ndarray.min(losses))\n",
    "bestGamma = gammaRange[bestGammaIdx]\n",
    "print(\"Best gamma value is: {}\".format(best))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Improving Logistic_regression\n",
    "\n",
    "We search the gamma parameter that minimize the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nbPoints = 20\n",
    "gammaRange = np.linspace(0, 5, nbPoints)\n",
    "losses = np.zeros(nbPoints)\n",
    "    \n",
    "for i in range(nbPoints):\n",
    "    gamma = gammaRange[i]\n",
    "    # TODO crossvalidation\n",
    "    #losses[i] = loss\n",
    "    print(\"gamma = {},  loss = {}\".format(gamma, loss))\n",
    "\n",
    "plt.plot(gammaRange, losses)\n",
    "bestGammaIdx = np.where(losses == np.ndarray.min(losses))\n",
    "bestGamma = gammaRange[bestGammaIdx]\n",
    "print(\"Best gamma value is: {}\".format(best))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improving Penalized Logistic Regression\n",
    "\n",
    "We need to optimize the parameters lambda and gamma in order to minimize the loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(568238, 30)\n"
     ]
    }
   ],
   "source": [
    "DATA_TEST_PATH = '../data/test.csv'\n",
    "_, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)\n",
    "print(tX_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare tX_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tXTe = normalize(tX_test)\n",
    "tXTe = np.hstack((np.ones((tX_test.shape[0],1)), tXTe))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "OUTPUT_PATH = '../output/out.csv'\n",
    "\n",
    "y_pred = predict_labels(weights, tXTe)\n",
    "\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
