{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Load the training data into feature matrix, class labels, and event ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from proj1_helpers import *\n",
    "DATA_TRAIN_PATH = '../data/train.csv'\n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features Preparation\n",
    " * Standardization\n",
    " * PCA ( TODO )\n",
    " * Polynomial basis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normal (250000, 30)\n",
      "basis (250000, 90)\n",
      "(250000, 90)\n",
      "(array([31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47,\n",
      "       48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64,\n",
      "       65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81,\n",
      "       82, 83, 84, 85, 86, 87, 88, 89]),)\n",
      "(array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
      "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]),)\n",
      "(250000, 59)\n"
     ]
    }
   ],
   "source": [
    "from helpers import *\n",
    "# Standardization\n",
    "tX_norm = normalize(tX)\n",
    "\n",
    "# Polynomial Basis\n",
    "degree = 3\n",
    "print(\"normal\", tX.shape)\n",
    "tX_poly = polynomialBasis(tX_norm, degree)\n",
    "tX_basis = tX_poly\n",
    "print(\"basis\", tX_basis.shape)\n",
    "\n",
    "# ---------- PCA test\n",
    "\n",
    "pcatX = plt.mlab.PCA(tX_basis)\n",
    "print(pcatX.Y.shape)\n",
    "num_feature = np.nonzero(np.cumsum(pcatX.fracs) > 0.9)\n",
    "num_useless = np.nonzero(np.cumsum(pcatX.fracs) < 0.9)\n",
    "print(num_feature)\n",
    "print(num_useless)\n",
    "tX_filtered = np.delete(tX_basis,num_useless, axis = 1)\n",
    "print(tX_filtered.shape)\n",
    "# -- pas conculant\n",
    "\n",
    "\n",
    "tXTr = np.hstack((np.ones((tX_basis.shape[0],1)), tX_basis))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1 over 30 | gamma:  0.0001\n",
      "  -> loss_tr: 0.30764899566867177\n",
      "  -> loss_te: 5.845172493870686\n",
      "Step 2 over 30 | gamma:  0.000137382379588\n",
      "  -> loss_tr: 0.3076515917627318\n",
      "  -> loss_te: 5.792404515540349\n",
      "Step 3 over 30 | gamma:  0.000188739182214\n"
     ]
    }
   ],
   "source": [
    "from cross_validation import *\n",
    "\n",
    "k_fold = 2\n",
    "nbPoints = 30\n",
    "lambdas = np.logspace(-4, 0, nbPoints)\n",
    "losses_tr = []\n",
    "losses_te = []\n",
    "\n",
    "#print(\"Gammas: {}\".format(gammas))\n",
    "\n",
    "i = 0    \n",
    "for lam in lambdas:\n",
    "    i = i + 1\n",
    "    print(\"Step\", i, \"over\", nbPoints, \"| gamma: \", lam)\n",
    "    loss_train = []\n",
    "    loss_test = []\n",
    "    initial_w = np.zeros((tXTr.shape[1]))\n",
    "     \n",
    "    for k in range (k_fold):\n",
    "        loss_tr, loss_te = cross_validation(y, tXTr, k_fold, k, lam, initial_w, 0, \"ridge_regression\")\n",
    "        loss_train.append(loss_tr)\n",
    "        loss_test.append(loss_te)\n",
    "        \n",
    "    \n",
    "    # rmse of the mean mse\n",
    "    loss_tr = np.sum(loss_train, axis=0)/k_fold\n",
    "    loss_te = np.sum(loss_test, axis=0)/k_fold\n",
    "    losses_tr.append(loss_tr)\n",
    "    losses_te.append(loss_te)\n",
    "    print(\"  -> loss_tr: {}\\n  -> loss_te: {}\".format(loss_tr, loss_te))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.semilogx(lambdas, losses_tr, marker=\".\", color='b', label='train error')\n",
    "plt.semilogx(lambdas, losses_te, marker=\".\", color='r', label='test error')\n",
    "plt.xlabel(\"Lambdas\")\n",
    "plt.ylabel(\"rmse\")\n",
    "plt.title(\"cross validation\")\n",
    "plt.legend(loc=2)\n",
    "plt.grid(True)\n",
    "plt.savefig(\"cross_validation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "=> Lambda : 10e-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(568238, 30)\n"
     ]
    }
   ],
   "source": [
    "DATA_TEST_PATH = '../data/test.csv'\n",
    "_, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)\n",
    "print(tX_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lambda_ = 0.001\n",
    "\n",
    "tXTr = np.hstack((np.ones((tX_basis.shape[0],1)), tX_basis))\n",
    "train_w, loss_tr = ridge_regression(y, tXTr, lambda_)\n",
    "\n",
    "tXTe = normalize(tX_test)\n",
    "tXTe = polynomialBasis(tXTe, 2)\n",
    "tXTe = np.delete(tX_basis, num_useless)\n",
    "tXTe = np.hstack((np.ones((tX_test.shape[0],1)), tXTe))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "OUTPUT_PATH = '../output/out.csv'\n",
    "\n",
    "y_pred = predict_labels(train_w, tXTe)\n",
    "\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
